---
title: "vocab composition"
author: "Samah"
date: "2024-05-05"
output: html_document
---

# Preprocessing 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(jsonlite)
library(tidyverse)
library(purrr)
library(ggrepel)
library(here)
library(irr)
source(here("..","helper.R"))
```

Read in correct data. 

```{r}
# pilot_data = read_csv("samah.varlogs.pilot.csv")
# full_data1 = read_csv("samah.varlogs.csv")
full_data = read_csv("redo.csv")
```

Apply the helper function to the jsonData column

```{r}
full_data$response <- sapply(full_data$response, extractValue)

full_data <- full_data %>% filter(trial_type == "survey-multi-choice")
full_data <- full_data %>%
  filter(!str_detect(block, "practice") & !str_detect(block, "attention") ) %>% 
  filter(!is.na(theword))
```

Read in language data. 

```{r}
test 
word_language_mappings <- read_csv("alllangs.csv") %>% 
  filter(!is.na(uni_lemma))  %>% 
  mutate(theword = uni_lemma) %>%
  select(theword, language)
```
Define mapping dictionaries
 
```{r }

# Apply the mapping function in helper.R to the response column
full_data$response_numeric <- mapply(map_categories, full_data$response, full_data$block)
```

```{r}
responsecount <- full_data %>% group_by(theword, block) %>% summarize(meanrating = mean(response_numeric), stdev = sd(response_numeric), count = n()) %>% ungroup() 

wide_responsecount <- responsecount %>%
  select(theword, block, count) %>%
  # filter(count > 5) %>%
  pivot_wider(names_from = block, values_from = count)


# languages <- merge(x = wide_responsecount, y = languages, by = "theword")
# languages = word_language_mappings

response_counts <- full_join(wide_responsecount, word_language_mappings)

```

# Inter-rater agreement

binomial and agreemment among raters

``` {r}
# Group by 'theword' and 'block'

#full_datas <- full_data %>% select(theword, subject, response, block)
full_datas <- full_data %>% select(theword, subject, response, block)


grouped_data <- full_datas %>%
  group_by(theword, block) %>%
  summarise(response_count = n(),
            most_common_response = max(table(response)),
            total_responses = n(),
            .groups = 'drop')

# proportion of agreement for most common response
grouped_data <- grouped_data %>%
  mutate(proportion_agreement = most_common_response / total_responses)

# Function to perform binomial test
perform_binom_test <- function(successes, total) {
  binom.test(successes, total, p = 0.7, alternative = "greater")
}

=
results <- grouped_data %>%
  rowwise() %>%
  mutate(binom_test = list(perform_binom_test(most_common_response, total_responses)),
         p_value = binom_test$p.value,
         significant = p_value < 0.05) %>%
  select(theword, block, proportion_agreement, p_value, significant)


print(results)

agreement <- grouped_data %>%
  group_by(block) %>%
  summarise(m = mean(proportion_agreement),
            se = sd(proportion_agreement) / sqrt(n()))

ggplot(data = agreement, aes(x = block, y = m)) +
  geom_col(fill = "skyblue", width = 0.5) +  # Narrow bars
  geom_errorbar(aes(ymin = m - se, ymax = m + se), width = 0.2) + 
  labs(x = "Block", y = "Proportion of Agreement", title = "Mean Proportion of Agreement by Block") +
  theme_minimal() +
  theme(aspect.ratio = 0.5) 

# specific dimensions
ggsave("agreement_plot.png", width = 5, height = 4)  

```

Cohen's Kappa: inter rater agreement:
Kappa.light is not working becuase we have a lot of NAs

``` {r }
solid_kappa <- full_data %>% filter(block == "solidity") 
# %>% select(theword, response_numeric, subject ) %>% pivot_wider(names_from = subject, values_from = response_numeric)


ratings_wide <- solid_kappa %>%
  select(theword, response_numeric, subject) %>%
  pivot_wider(names_from = subject, values_from = response_numeric)

# matrix is compatible with irr package functions) ?
ratings_matrix <- as.matrix(ratings_wide %>% select(-theword))

# kappam.light() can handle NAs ?
kappa_result <- kappam.light(ratings_matrix)
print(kappa_result)


```

using pairwise cohen's kappa: 
``` {r }

ratings_wide <- solid_kappa %>%
  select(theword, response_numeric, subject) %>%
  pivot_wider(names_from = subject, values_from = response_numeric)

#create all unique pairs of raters
raters <- colnames(ratings_wide)[-1]  # exclude "theword" 
pairs <- combn(raters, 2, simplify = FALSE)

# calculate pairwise Cohen's Kappa
pairwise_kappas <- sapply(pairs, function(pair) {
  ratings_pair <- ratings_wide %>%
    select(theword, all_of(pair)) %>%
    drop_na()
  
  #are there enough ratings to calculate kappa?
  if (nrow(ratings_pair) > 1) {
    kappa2(as.matrix(ratings_pair[, -1]), weight = "unweighted")$value
  } else {
    NA 
  }
})


mean_kappa <- mean(pairwise_kappas, na.rm = TRUE)
print(mean_kappa)

```
visualizing Kappa values: 
``` {r }

pairwise_results <- data.frame(
  Pair = sapply(pairs, function(x) paste(x, collapse = "-")),
  Kappa = pairwise_kappas
)
print(pairwise_results)


library(ggplot2)
ggplot(pairwise_results, aes(x = Kappa)) +
  geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Pairwise Kappa Scores", x = "Kappa", y = "Frequency") +
  theme_minimal()

```

# Data processing 

proportions :

``` {r}

full_data <- full_data %>% group_by(theword, block) %>%
  mutate(totcount = n()) %>% ungroup()
# how many ratings per response per block
category_counts <- full_data %>%
  group_by(theword, block, response, totcount) %>%
  summarise(count = n(), .groups = 'drop') 

prop_shape <- category_counts %>% filter(response == "shape")


category_counts <- category_counts %>%
  mutate(proportion = count/totcount)

#languages = word_language_mappings
lang_df <- full_join(category_counts, word_language_mappings) %>% filter( !is.na(theword), !is.na(language))

```

divide the lang_df by block:
shared words amongst (solidity, syntax, and category) based on proportion

```{r }
solid_df <- lang_df %>% filter(response == "solid")
count_df <- lang_df %>% filter(response == "count noun")
shape_df <- lang_df %>% filter(response == "shape")



inner_join(solid_df %>% filter(proportion <= 0.5), count_df %>% filter(proportion <= 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion > 0.5), count_df %>% filter(proportion > 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion <= 0.5), count_df %>% filter(proportion > 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion > 0.5), count_df %>% filter(proportion <= 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion <= 0.5), shape_df %>% filter(proportion <= 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion > 0.5), shape_df %>% filter(proportion > 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion <= 0.5), shape_df %>% filter(proportion > 0.5) , by= "theword") %>% select(theword) %>% unique()

inner_join(solid_df %>% filter(proportion > 0.5), shape_df %>% filter(proportion <= 0.5) , by= "theword") %>% select(theword) %>% unique()



dfs <- list(solid_df, count_df, shape_df)
names <- c("solid", "count", "shape")
conditions <- c("low", "high")

# Generate all unique pairs of dataframe and condition combinations
comparison_combinations <- expand.grid(
  df1 = names, df2 = names,
  prop1 = conditions, prop2 = conditions,
  stringsAsFactors = FALSE
) %>%
  filter(df1 != df2)  # no same dataframe comparisons

# Apply over each combination
results <- comparison_combinations %>%
  pmap_dfr(~ find_shared_words(
    dfs[[which(names == ..1)]],
    dfs[[which(names == ..2)]],
    ..1, ..2, ..3, ..4
  ))
 print(results)

results %>% group_by(source1, source2, condition1, condition2) %>% summarize(count = n())

```

randomly sample 50 words: 

``` {r}
randm_solid <- category_counts %>%
  filter(block == "solidity") %>% 
  {                               
    sampled_words <- sample(unique(.$theword), 50, replace = FALSE)
    filter(., theword %in% sampled_words)
  }

randm_syntax <- category_counts %>% filter(block == "count_mass") %>% 
    sampled_words <- sample(unique(.$theword), 50, replace = FALSE)
    filter(., theword %in% sampled_words)
  }

randm_categ <- category_counts %>% filter(block == "category_organization") %>% 
    sampled_words <- sample(unique(.$theword), 50, replace = FALSE)
    filter(., theword %in% sampled_words)
  }
```
reorder

```{r}

solid_proportions <- randm_solid %>%
  filter(response == "solid") %>%
  select(theword, solid_proportion = proportion)

# merge the proportion of "solid" back into the main data frame
randm_solid <- randm_solid %>%
  left_join(solid_proportions, by = "theword") %>%
  mutate(solid_proportion = replace_na(solid_proportion, 0))

# reorder 'theword' based on 'solid_proportion'
randm_solid <- randm_solid %>% 
  mutate(theword = fct_reorder(theword, solid_proportion, .desc = TRUE))

#length(unique(languages$theword))

```
# Plots

```{r}
ggplot(randm_solid, aes(x = theword, y = proportion, fill = response)) +           geom_bar(position = "stack", stat = "identity") + coord_flip()

ggplot(randm_syntax, aes(x = theword, y = proportion, fill = response)) +           geom_bar(position = "stack", stat = "identity") + coord_flip()

ggplot(randm_categ, aes(x = theword, y = proportion, fill = response)) +           geom_bar(position = "stack", stat = "identity") + coord_flip()
```

ordered

```{r}

ggplot(randm_solid, aes(x = theword, y = proportion, fill = response)) +
  geom_bar(position = "stack", stat = "identity") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
# rotate x-axis text for better readability

```

``` {r}

# proportion_solid<- category_counts %>% filter(response == "solid")
# proportion_count <- category_counts %>% filter(response == "count noun")
# proportion_shape <-  category_counts %>% filter(response == "shape")

lang_df1 <- lang_df %>% filter(response == "solid" | response == "count noun" | response == "shape" | response == "none of these" )
lang_df2 <- lang_df %>% filter(response == "shape" | response == "material" | response == "none of these" | response == "color")


# Create combined density plot
ggplot(lang_df1, aes(x = proportion, color = response, fill = response)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ language) +
  labs(
    title = "Density of Proportions by Language",
    x = "Proportion Value",
    y = "Density (words)"
  ) +
  theme_minimal()

# Create combined density plot
ggplot(lang_df2, aes(x = proportion, color = response, fill = response)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ language) +
  labs(
    title = "Density of Proportions by Language",
    x = "Proportion Value",
    y = "Density (words)"
  ) +
  theme_minimal()

```

```{r}
ggplot(filter(lang_df1, response != "none of these"),
       aes(x = proportion, color = response, fill = response)) +
  geom_density(alpha = 0.5, aes(y = after_stat(count))) +
  # geom_histogram(position = "dodge", binwidth = .05)
  facet_wrap(~ language) +
  labs(
    title = "Density of Proportions by Language",
    x = "Proportion Value",
    y = "Density"
  ) +
  theme_minimal()
```


