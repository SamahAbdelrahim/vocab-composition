---
title: "vocab composition"
author: "Samah"
date: "2024-05-05"
output: html_document
---

# Preprocessing 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(jsonlite)
library(tidyverse)
library(ggrepel)
library(here)
source(here("..","helper.R"))
```

Read in correct data. 

```{r}
# pilot_data = read_csv("samah.varlogs.pilot.csv")
# full_data1 = read_csv("samah.varlogs.csv")
full_data = read_csv("redo.csv")
```

Apply the helper function to the jsonData column

```{r}
full_data$response <- sapply(full_data$response, extractValue)

full_data <- full_data %>% filter(trial_type == "survey-multi-choice")
full_data <- full_data %>%
  filter(!str_detect(block, "practice") & !str_detect(block, "attention") ) %>% 
  filter(!is.na(theword))
```

Read in language data. 

```{r}
test 
word_language_mappings <- read_csv("alllangs.csv") %>% 
  filter(!is.na(uni_lemma))  %>% 
  mutate(theword = uni_lemma) %>%
  select(theword, language)
```
Define mapping dictionaries
 
```{r }

# Apply the mapping function in helper.R to the response column
full_data$response_numeric <- mapply(map_categories, full_data$response, full_data$block)
```

```{r}
responsecount <- full_data %>% group_by(theword, block) %>% summarize(meanrating = mean(response_numeric), stdev = sd(response_numeric), count = n()) %>% ungroup() 

wide_responsecount <- responsecount %>%
  select(theword, block, count) %>%
  # filter(count > 5) %>%
  pivot_wider(names_from = block, values_from = count)


# languages <- merge(x = wide_responsecount, y = languages, by = "theword")
# languages = word_language_mappings

response_counts <- full_join(wide_responsecount, word_language_mappings)

```

# Inter-rater agreement

binomial and agreemment among raters

``` {r}
# Group by 'theword' and 'block'

#full_datas <- full_data %>% select(theword, subject, response, block)
full_datas <- full_data %>% select(theword, subject, response, block)


grouped_data <- full_datas %>%
  group_by(theword, block) %>%
  summarise(response_count = n(),
            most_common_response = max(table(response)),
            total_responses = n(),
            .groups = 'drop')

# Calculate the proportion of agreement for the most common response
grouped_data <- grouped_data %>%
  mutate(proportion_agreement = most_common_response / total_responses)

# Function to perform binomial test
perform_binom_test <- function(successes, total) {
  binom.test(successes, total, p = 0.7, alternative = "greater")
}

# Apply the binomial test for each group
results <- grouped_data %>%
  rowwise() %>%
  mutate(binom_test = list(perform_binom_test(most_common_response, total_responses)),
         p_value = binom_test$p.value,
         significant = p_value < 0.05) %>%
  select(theword, block, proportion_agreement, p_value, significant)

# View the results
print(results)

agreement <- grouped_data %>%
  group_by(block) %>%
  summarise(m = mean(proportion_agreement),
            se = sd(proportion_agreement) / sqrt(n()))

ggplot(data = agreement, aes(x = block, y = m)) +
  geom_col(fill = "skyblue", width = 0.5) +  # Narrow bars
  geom_errorbar(aes(ymin = m - se, ymax = m + se), width = 0.2) +  # Error bars
  labs(x = "Block", y = "Proportion of Agreement", title = "Mean Proportion of Agreement by Block") +
  theme_minimal() +
  theme(aspect.ratio = 0.5) 

# Save with specific dimensions
ggsave("agreement_plot.png", width = 5, height = 4)  

```

# Data processing 

proportions :

``` {r}

full_data <- full_data %>% group_by(theword, block) %>%
  mutate(totcount = n()) %>% ungroup()
# how many ratings per response per block
category_counts <- full_data %>%
  group_by(theword, block, response, totcount) %>%
  summarise(count = n(), .groups = 'drop') 

prop_shape <- category_counts %>% filter(response == "shape")


category_counts <- category_counts %>%
  mutate(proportion = count/totcount)

#languages = word_language_mappings
lang_df <- full_join(category_counts, word_language_mappings) %>% filter( !is.na(theword), !is.na(language))

```
randomly sample 50 words: 

``` {r}
randm_solid <- category_counts %>%
  filter(block == "solidity") %>% # Step 1: Filter by block
  {                               # Step 2: Select 50 random unique theword values and filter the dataframe
    sampled_words <- sample(unique(.$theword), 50, replace = FALSE)
    filter(., theword %in% sampled_words)
  }

randm_syntax <- category_counts %>% filter(block == "count_mass") %>% # Step 1: Filter by block
  {                               # Step 2: Select 50 random unique theword values and filter the dataframe
    sampled_words <- sample(unique(.$theword), 50, replace = FALSE)
    filter(., theword %in% sampled_words)
  }

randm_categ <- category_counts %>% filter(block == "category_organization") %>% # Step 1: Filter by block
  {                               # Step 2: Select 50 random unique theword values and filter the dataframe
    sampled_words <- sample(unique(.$theword), 50, replace = FALSE)
    filter(., theword %in% sampled_words)
  }
```
reorder

```{r}
# Step 1: Calculate the proportion of "solid" for each word
solid_proportions <- randm_solid %>%
  filter(response == "solid") %>%
  select(theword, solid_proportion = proportion)

# Step 2: Merge the proportion of "solid" back into the main data frame
randm_solid <- randm_solid %>%
  left_join(solid_proportions, by = "theword") %>%
  mutate(solid_proportion = replace_na(solid_proportion, 0))

# Step 3: Reorder 'theword' based on 'solid_proportion'
randm_solid <- randm_solid %>% 
  mutate(theword = fct_reorder(theword, solid_proportion, .desc = TRUE))

#length(unique(languages$theword))

```
# Plots

```{r}
ggplot(randm_solid, aes(x = theword, y = proportion, fill = response)) +           geom_bar(position = "stack", stat = "identity") + coord_flip()

ggplot(randm_syntax, aes(x = theword, y = proportion, fill = response)) +           geom_bar(position = "stack", stat = "identity") + coord_flip()

ggplot(randm_categ, aes(x = theword, y = proportion, fill = response)) +           geom_bar(position = "stack", stat = "identity") + coord_flip()
```

ordered

```{r}
# Step 4: Create the plot
ggplot(randm_solid, aes(x = theword, y = proportion, fill = response)) +
  geom_bar(position = "stack", stat = "identity") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Optional: Rotate x-axis text for better readability

```

``` {r}

# proportion_solid<- category_counts %>% filter(response == "solid")
# proportion_count <- category_counts %>% filter(response == "count noun")
# proportion_shape <-  category_counts %>% filter(response == "shape")

lang_df1 <- lang_df %>% filter(response == "solid" | response == "count noun" | response == "shape" | response == "none of these" )
lang_df2 <- lang_df %>% filter(response == "shape" | response == "material" | response == "none of these" | response == "color")


# Create combined density plot
ggplot(lang_df1, aes(x = proportion, color = response, fill = response)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ language) +
  labs(
    title = "Density of Proportions by Language",
    x = "Proportion Value",
    y = "Density (words)"
  ) +
  theme_minimal()

# Create combined density plot
ggplot(lang_df2, aes(x = proportion, color = response, fill = response)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ language) +
  labs(
    title = "Density of Proportions by Language",
    x = "Proportion Value",
    y = "Density (words)"
  ) +
  theme_minimal()

```

```{r}
ggplot(filter(lang_df1, response != "none of these"),
       aes(x = proportion, color = response, fill = response)) +
  geom_density(alpha = 0.5, aes(y = after_stat(count))) +
  # geom_histogram(position = "dodge", binwidth = .05)
  facet_wrap(~ language) +
  labs(
    title = "Density of Proportions by Language",
    x = "Proportion Value",
    y = "Density"
  ) +
  theme_minimal()
```

